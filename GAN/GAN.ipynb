{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/maple/Documents/Capstone/code',\n",
       " '/Users/maple/anaconda3/envs/NLP/lib/python37.zip',\n",
       " '/Users/maple/anaconda3/envs/NLP/lib/python3.7',\n",
       " '/Users/maple/anaconda3/envs/NLP/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/maple/anaconda3/envs/NLP/lib/python3.7/site-packages',\n",
       " '/Users/maple/anaconda3/envs/NLP/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/maple/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://www.rd.com/health/wellness/life-coache...</td>\n",
       "      <td>Charlotte Hilton Andersen Dec 19 You’re not re...</td>\n",
       "      <td>2019-03-08 09:53:05.567228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://partners.magento.com/portal/customer/a...</td>\n",
       "      <td>Login or Create an Account If you have an acco...</td>\n",
       "      <td>2019-06-13 17:40:44.757068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://yahoo.brand.edgar-online.com/DisplayFi...</td>\n",
       "      <td>Last Trade: $0.17 Change: 0.00 (0.00%) Trade T...</td>\n",
       "      <td>2019-03-28 19:04:32.921537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://www.forbes.com/sites/alejandrocremades...</td>\n",
       "      <td>He Sold His First Startup To Yahoo, His Second...</td>\n",
       "      <td>2019-06-14 12:26:40.624181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.bloomberg.com/research/stocks/priv...</td>\n",
       "      <td>April 19, 2019 3:34 AM ET Company Overview of ...</td>\n",
       "      <td>2019-04-19 07:34:13.488132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.rd.com/health/wellness/life-coache...   \n",
       "1  https://partners.magento.com/portal/customer/a...   \n",
       "2  https://yahoo.brand.edgar-online.com/DisplayFi...   \n",
       "3  https://www.forbes.com/sites/alejandrocremades...   \n",
       "4  https://www.bloomberg.com/research/stocks/priv...   \n",
       "\n",
       "                                   extracted_content  \\\n",
       "0  Charlotte Hilton Andersen Dec 19 You’re not re...   \n",
       "1  Login or Create an Account If you have an acco...   \n",
       "2  Last Trade: $0.17 Change: 0.00 (0.00%) Trade T...   \n",
       "3  He Sold His First Startup To Yahoo, His Second...   \n",
       "4  April 19, 2019 3:34 AM ET Company Overview of ...   \n",
       "\n",
       "                    timestamp  \n",
       "0  2019-03-08 09:53:05.567228  \n",
       "1  2019-06-13 17:40:44.757068  \n",
       "2  2019-03-28 19:04:32.921537  \n",
       "3  2019-06-14 12:26:40.624181  \n",
       "4  2019-04-19 07:34:13.488132  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data-random_sample_with_content_10000_english.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maple/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte Hilton Andersen Dec 19 You’re not re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Login or Create an Account If you have an acco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Last Trade: $0.17 Change: 0.00 (0.00%) Trade T...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>He Sold His First Startup To Yahoo, His Second...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>April 19, 2019 3:34 AM ET Company Overview of ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   extracted_content  index\n",
       "0  Charlotte Hilton Andersen Dec 19 You’re not re...      0\n",
       "1  Login or Create an Account If you have an acco...      1\n",
       "2  Last Trade: $0.17 Change: 0.00 (0.00%) Trade T...      2\n",
       "3  He Sold His First Startup To Yahoo, His Second...      3\n",
       "4  April 19, 2019 3:34 AM ET Company Overview of ...      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = data[['extracted_content']]\n",
    "documents['index'] = documents.index\n",
    "print(documents.shape)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm') #en_core_web_sm\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def tokenize(sent):\n",
    "  tokens = tokenizer(sent)\n",
    "  return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset \n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "#tokens, all_tokens = tokenize_dataset(list(documents['extracted_content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "#pkl.dump(tokens, open(\"../data/sent_tokens.p\", \"wb\"))\n",
    "#pkl.dump(all_tokens, open(\"../data/all_tokens.p\", \"wb\"))\n",
    "all_tokens = pkl.load(open(\"../data/all_tokens.p\", \"rb\"))\n",
    "tokens = pkl.load(open(\"../data/sent_tokens.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tokens)==10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "def build_vocab(all_tokens, vocab_size):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id, id2token = build_vocab(all_tokens, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indices = token2index_dataset(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Prepare_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        #assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        #label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Prepare_Dataset(token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Prepare_Dataset at 0x164b4be90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list = [len(data) for data in token_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "np.median(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset=train_dataset, \n",
    "                               batch_size = 32, \n",
    "                               collate_fn=data_func,\n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 500])\n"
     ]
    }
   ],
   "source": [
    "for i, (data, lengths) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    #print(lengths)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_max_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class TextCNN(BasicModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.config = config\n",
    "        self.out_channel = config.out_channel\n",
    "        self.conv3 = nn.Conv2d(1, 1, (3, config.word_embedding_dimension))\n",
    "        self.conv4 = nn.Conv2d(1, 1, (4, config.word_embedding_dimension))\n",
    "        self.conv5 = nn.Conv2d(1, 1, (5, config.word_embedding_dimension))\n",
    "        self.Max3_pool = nn.MaxPool2d((self.config.sentence_max_size-3+1, 1))\n",
    "        self.Max4_pool = nn.MaxPool2d((self.config.sentence_max_size-4+1, 1))\n",
    "        self.Max5_pool = nn.MaxPool2d((self.config.sentence_max_size-5+1, 1))\n",
    "        self.linear1 = nn.Linear(3, config.label_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        # Convolution\n",
    "        x1 = F.relu(self.conv3(x))\n",
    "        x2 = F.relu(self.conv4(x))\n",
    "        x3 = F.relu(self.conv5(x))\n",
    "\n",
    "        # Pooling\n",
    "        x1 = self.Max3_pool(x1)\n",
    "        x2 = self.Max4_pool(x2)\n",
    "        x3 = self.Max5_pool(x3)\n",
    "\n",
    "        # capture and concatenate the features\n",
    "        x = torch.cat((x1, x2, x3), -1)\n",
    "        x = x.view(batch, 1, -1)\n",
    "\n",
    "        # project the features to the labels\n",
    "        x = self.linear1(x)\n",
    "        x = x.view(-1, self.config.label_num)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, padding_idx, gpu=False):\n",
    "        super(LSTMGenerator, self).__init__()\n",
    "        self.name = 'vanilla'\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.temperature = 1.0\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp, hidden, need_hidden=False):\n",
    "        \"\"\"\n",
    "        Embeds input and applies LSTM\n",
    "        :param inp: batch_size * seq_len\n",
    "        :param hidden: (h, c)\n",
    "        :param need_hidden: if return hidden, use for sampling\n",
    "        \"\"\"\n",
    "        emb = self.embeddings(inp)  # batch_size * len * embedding_dim\n",
    "        if len(inp.size()) == 1:\n",
    "            emb = emb.unsqueeze(1)  # batch_size * 1 * embedding_dim\n",
    "\n",
    "        out, hidden = self.lstm(emb, hidden)  # out: batch_size * seq_len * hidden_dim\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)  # out: (batch_size * len) * hidden_dim\n",
    "        out = self.lstm2out(out)  # batch_size * seq_len * vocab_size\n",
    "        out = self.temperature * out  # temperature\n",
    "        pred = self.softmax(out)\n",
    "\n",
    "        if need_hidden:\n",
    "            return pred, hidden\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    def sample(self, num_samples, batch_size, start_letter=cfg.start_letter):\n",
    "        \"\"\"\n",
    "        Samples the network and returns num_samples samples of length max_seq_len.\n",
    "        :return samples: num_samples * max_seq_length (a sampled sequence in each row)\n",
    "        \"\"\"\n",
    "        num_batch = num_samples // batch_size + 1 if num_samples != batch_size else 1\n",
    "        samples = torch.zeros(num_batch * batch_size, self.max_seq_len).long()\n",
    "\n",
    "        # 用LSTM随机生成batch_size个句子，生成下一个词的时候是按多项式分布来选择的，而不是概率最大那个\n",
    "        for b in range(num_batch):\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "            inp = torch.LongTensor([start_letter] * batch_size)\n",
    "            if self.gpu:\n",
    "                inp = inp.cuda()\n",
    "\n",
    "            for i in range(self.max_seq_len):\n",
    "                out, hidden = self.forward(inp, hidden, need_hidden=True)  # out: num_samples * vocab_size\n",
    "                next_token = torch.multinomial(torch.exp(out), 1)  # num_samples * 1 (sampling from each row)\n",
    "                samples[b * batch_size:(b + 1) * batch_size, i] = next_token.view(-1)\n",
    "                inp = next_token.view(-1)\n",
    "        samples = samples[:num_samples]\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                if cfg.gen_init == 'uniform':\n",
    "                    torch.nn.init.uniform_(param, a=-0.05, b=0.05)\n",
    "                elif cfg.gen_init == 'normal':\n",
    "                    torch.nn.init.normal_(param, std=stddev)\n",
    "                elif cfg.gen_init == 'truncated_normal':\n",
    "                    truncated_normal_(param, std=stddev)\n",
    "\n",
    "    def init_oracle(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad:\n",
    "                torch.nn.init.normal_(param, mean=0, std=1)\n",
    "\n",
    "    def init_hidden(self, batch_size=batch_size):\n",
    "        h = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "        c = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "\n",
    "        if self.gpu:\n",
    "            return h.cuda(), c.cuda()\n",
    "        else:\n",
    "            return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import config as cfg\n",
    "#from utils.helpers import truncated_normal_\n",
    "\n",
    "class GRUDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, vocab_size, hidden_dim, feature_dim, max_seq_len, padding_idx,\n",
    "                 gpu=False, dropout=0.2):\n",
    "        super(GRUDiscriminator, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.padding_idx = padding_idx\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=dropout)\n",
    "        self.gru2hidden = nn.Linear(2 * 2 * hidden_dim, feature_dim)\n",
    "        self.feature2out = nn.Linear(feature_dim, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h = autograd.Variable(torch.zeros(2 * 2 * 1, batch_size, self.hidden_dim))\n",
    "\n",
    "        if self.gpu:\n",
    "            return h.cuda()\n",
    "        else:\n",
    "            return h\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Get final feature of discriminator\n",
    "        :param inp: batch_size * seq_len\n",
    "        :return pred: batch_size * seq_len * vocab_size\n",
    "        \"\"\"\n",
    "        feature = self.get_feature(inp)\n",
    "        pred = self.feature2out(self.dropout(feature))\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def get_feature(self, inp):\n",
    "        \"\"\"\n",
    "        Get feature vector of given sentences\n",
    "        :param inp: batch_size * max_seq_len\n",
    "        :return: batch_size * feature_dim\n",
    "        \"\"\"\n",
    "        hidden = self.init_hidden(inp.size(0))\n",
    "\n",
    "        emb = self.embeddings(input)  # batch_size * seq_len * embedding_dim\n",
    "        emb = emb.permute(1, 0, 2)  # seq_len * batch_size * embedding_dim\n",
    "        _, hidden = self.gru(emb, hidden)  # 4 * batch_size * hidden_dim\n",
    "        hidden = hidden.permute(1, 0, 2).contiguous()  # batch_size * 4 * hidden_dim\n",
    "        out = self.gru2hidden(hidden.view(-1, 4 * self.hidden_dim))  # batch_size * 4 * hidden_dim\n",
    "        feature = torch.tanh(out)  # batch_size * feature_dim\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                #if cfg.dis_init == 'uniform':\n",
    "                torch.nn.init.uniform_(param, a=-0.05, b=0.05)\n",
    "                #elif cfg.dis_init == 'normal':\n",
    "                    #torch.nn.init.normal_(param, std=stddev)\n",
    "                #elif cfg.dis_init == 'truncated_normal':\n",
    "                    #truncated_normal_(param, std=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dimension=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.config = config\n",
    "        #self.out_channel = config.out_channel\n",
    "        self.conv3 = nn.Conv2d(1, 1, (3, word_embedding_dimension))\n",
    "        self.conv4 = nn.Conv2d(1, 1, (4, word_embedding_dimension))\n",
    "        self.conv5 = nn.Conv2d(1, 1, (5, word_embedding_dimension))\n",
    "        self.Max3_pool = nn.MaxPool2d((500-3+1, 1))\n",
    "        self.Max4_pool = nn.MaxPool2d((500-4+1, 1))\n",
    "        self.Max5_pool = nn.MaxPool2d((500-5+1, 1))\n",
    "        #self.linear1 = nn.Linear(3, config.label_num)\n",
    "        \n",
    "        #self.tconv1 = nn.ConvTranspose2d(74, 1024, 1, 1, bias=False)\n",
    "        #self.bn1 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        #self.tconv2 = nn.ConvTranspose2d(1024, 128, 7, 1, bias=False)\n",
    "        #self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        #self.tconv3 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n",
    "        #self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        #self.tconv4 = nn.ConvTranspose2d(64, 1, 4, 2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.bn1(self.tconv1(x)))\n",
    "        #x = F.relu(self.bn2(self.tconv2(x)))\n",
    "        #x = F.relu(self.bn3(self.tconv3(x)))\n",
    "\n",
    "        #img = torch.sigmoid(self.tconv4(x))\n",
    "        batch = x.shape[0]\n",
    "        # Convolution\n",
    "        x1 = F.relu(self.conv3(x))\n",
    "        x2 = F.relu(self.conv4(x))\n",
    "        x3 = F.relu(self.conv5(x))\n",
    "\n",
    "        # Pooling\n",
    "        x1 = self.Max3_pool(x1)\n",
    "        x2 = self.Max4_pool(x2)\n",
    "        x3 = self.Max5_pool(x3)\n",
    "\n",
    "        # capture and concatenate the features\n",
    "        x = torch.cat((x1, x2, x3), -1)\n",
    "        x = x.view(batch, 1, -1)\n",
    "\n",
    "        # project the features to the labels\n",
    "        x = self.linear1(x)\n",
    "        x = x.view(-1, label_num)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(1024, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.conv(x))\n",
    "\n",
    "        return output\n",
    "\n",
    "class QHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1024, 128, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv_disc = nn.Conv2d(128, 10, 1)\n",
    "        self.conv_mu = nn.Conv2d(128, 2, 1)\n",
    "        self.conv_var = nn.Conv2d(128, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n",
    "\n",
    "        disc_logits = self.conv_disc(x).squeeze()\n",
    "\n",
    "        mu = self.conv_mu(x).squeeze()\n",
    "        var = torch.exp(self.conv_var(x).squeeze())\n",
    "\n",
    "        return disc_logits, mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 32,# Batch size.\n",
    "    'num_epochs': 10,# Number of epochs to train for.\n",
    "    'learning_rate': 2e-4,# Learning rate.\n",
    "    'beta1': 0.5,\n",
    "    'beta2': 0.999,\n",
    "    'save_epoch' : 25,# After how many epochs to save checkpoints and generate test output.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['num_z'] = 62\n",
    "params['num_dis_c'] = 1\n",
    "params['dis_c_dim'] = 10\n",
    "params['num_con_c'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalNLLLoss:\n",
    "    \"\"\"\n",
    "    Calculate the negative log likelihood\n",
    "    of normal distribution.\n",
    "    This needs to be minimised.\n",
    "    Treating Q(cj | x) as a factored Gaussian.\n",
    "    \"\"\"\n",
    "    def __call__(self, x, mu, var):\n",
    "        \n",
    "        logli = -0.5 * (var.mul(2 * np.pi) + 1e-6).log() - (x - mu).pow(2).div(var.mul(2.0) + 1e-6)\n",
    "        nll = -(logli.sum(1).mean())\n",
    "\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    Initialise weights of the model.\n",
    "    \"\"\"\n",
    "    if(type(m) == nn.ConvTranspose2d or type(m) == nn.Conv2d):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif(type(m) == nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionQ_con = NormalNLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (conv3): Conv2d(1, 1, kernel_size=(3, 500), stride=(1, 1))\n",
      "  (conv4): Conv2d(1, 1, kernel_size=(4, 500), stride=(1, 1))\n",
      "  (conv5): Conv2d(1, 1, kernel_size=(5, 500), stride=(1, 1))\n",
      "  (Max3_pool): MaxPool2d(kernel_size=(498, 1), stride=(498, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (Max4_pool): MaxPool2d(kernel_size=(497, 1), stride=(497, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (Max5_pool): MaxPool2d(kernel_size=(496, 1), stride=(496, 1), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Discriminator()\n",
      "DHead(\n",
      "  (conv): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "QHead(\n",
      "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_disc): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_mu): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv_var): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "-------------------------\n",
      "Starting Training Loop...\n",
      "\n",
      "Epochs: 10\n",
      "Batch Size: 32\n",
      "Length of Data Loader: 313\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 1 1024, but got 2-dimensional input of size [32, 500] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-656c7ffd22ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mprobs_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterionD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Calculate gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-68981f9d9273>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 1 1024, but got 2-dimensional input of size [32, 500] instead"
     ]
    }
   ],
   "source": [
    "# Initialise the network.\n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "discriminator.apply(weights_init)\n",
    "print(discriminator)\n",
    "\n",
    "netD = DHead().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "\n",
    "netQ = QHead().to(device)\n",
    "netQ.apply(weights_init)\n",
    "print(netQ)\n",
    "\n",
    "# Loss for discrimination between real and fake images.\n",
    "criterionD = nn.BCELoss()\n",
    "# Loss for discrete latent code.\n",
    "criterionQ_dis = nn.CrossEntropyLoss()\n",
    "# Loss for continuous latent code.\n",
    "criterionQ_con = NormalNLLLoss()\n",
    "\n",
    "# Adam optimiser is used.\n",
    "optimD = optim.Adam([{'params': discriminator.parameters()}, {'params': netD.parameters()}], lr=params['learning_rate'], betas=(params['beta1'], params['beta2']))\n",
    "optimG = optim.Adam([{'params': netG.parameters()}, {'params': netQ.parameters()}], lr=params['learning_rate'], betas=(params['beta1'], params['beta2']))\n",
    "\n",
    "# Fixed Noise\n",
    "z = torch.randn(100, params['num_z'], 1, 1, device=device)\n",
    "fixed_noise = z\n",
    "if(params['num_dis_c'] != 0):\n",
    "    idx = np.arange(params['dis_c_dim']).repeat(10)\n",
    "    dis_c = torch.zeros(100, params['num_dis_c'], params['dis_c_dim'], device=device)\n",
    "    for i in range(params['num_dis_c']):\n",
    "        dis_c[torch.arange(0, 100), i, idx] = 1.0\n",
    "\n",
    "    dis_c = dis_c.view(100, -1, 1, 1)\n",
    "\n",
    "    fixed_noise = torch.cat((fixed_noise, dis_c), dim=1)\n",
    "\n",
    "if(params['num_con_c'] != 0):\n",
    "    con_c = torch.rand(100, params['num_con_c'], 1, 1, device=device) * 2 - 1\n",
    "    fixed_noise = torch.cat((fixed_noise, con_c), dim=1)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# List variables to store results pf training.\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "print(\"-\"*25)\n",
    "print(\"Starting Training Loop...\\n\")\n",
    "print('Epochs: %d\\nBatch Size: %d\\nLength of Data Loader: %d'.format()%(params['num_epochs'], params['batch_size'], len(train_loader)))\n",
    "print(\"-\"*25)\n",
    "\n",
    "start_time = time.time()\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(params['num_epochs']):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for i, (data, _) in enumerate(train_loader, 0):\n",
    "        # Get batch size\n",
    "        b_size = data.size(0)\n",
    "        # Transfer data tensor to GPU/CPU (device)\n",
    "        real_data = data.to(device)\n",
    "\n",
    "        # Updating discriminator and DHead\n",
    "        optimD.zero_grad()\n",
    "        # Real data\n",
    "        label = torch.full((b_size, ), real_label, device=device)\n",
    "        output1 = discriminator(real_data)\n",
    "        probs_real = netD(output1).view(-1)\n",
    "        loss_real = criterionD(probs_real, label)\n",
    "        # Calculate gradients.\n",
    "        loss_real.backward()\n",
    "\n",
    "        # Fake data\n",
    "        label.fill_(fake_label)\n",
    "        noise, idx = noise_sample(params['num_dis_c'], params['dis_c_dim'], params['num_con_c'], params['num_z'], b_size, device)\n",
    "        fake_data = netG(noise)\n",
    "        output2 = discriminator(fake_data.detach())\n",
    "        probs_fake = netD(output2).view(-1)\n",
    "        loss_fake = criterionD(probs_fake, label)\n",
    "        # Calculate gradients.\n",
    "        loss_fake.backward()\n",
    "\n",
    "        # Net Loss for the discriminator\n",
    "        D_loss = loss_real + loss_fake\n",
    "        # Update parameters\n",
    "        optimD.step()\n",
    "\n",
    "        # Updating Generator and QHead\n",
    "        optimG.zero_grad()\n",
    "\n",
    "        # Fake data treated as real.\n",
    "        output = discriminator(fake_data)\n",
    "        label.fill_(real_label)\n",
    "        probs_fake = netD(output).view(-1)\n",
    "        gen_loss = criterionD(probs_fake, label)\n",
    "\n",
    "        q_logits, q_mu, q_var = netQ(output)\n",
    "        target = torch.LongTensor(idx).to(device)\n",
    "        # Calculating loss for discrete latent code.\n",
    "        dis_loss = 0\n",
    "        for j in range(params['num_dis_c']):\n",
    "            dis_loss += criterionQ_dis(q_logits[:, j*10 : j*10 + 10], target[j])\n",
    "\n",
    "        # Calculating loss for continuous latent code.\n",
    "        con_loss = 0\n",
    "        if (params['num_con_c'] != 0):\n",
    "            con_loss = criterionQ_con(noise[:, params['num_z']+ params['num_dis_c']*params['dis_c_dim'] : ].view(-1, params['num_con_c']), q_mu, q_var)*0.1\n",
    "\n",
    "        # Net loss for generator.\n",
    "        G_loss = gen_loss + dis_loss + con_loss\n",
    "        # Calculate gradients.\n",
    "        G_loss.backward()\n",
    "        # Update parameters.\n",
    "        optimG.step()\n",
    "\n",
    "        # Check progress of training.\n",
    "        if i != 0 and i%100 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch+1, params['num_epochs'], i, len(dataloader), \n",
    "                    D_loss.item(), G_loss.item()))\n",
    "\n",
    "        # Save the losses for plotting.\n",
    "        G_losses.append(G_loss.item())\n",
    "        D_losses.append(D_loss.item())\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(\"Time taken for Epoch %d: %.2fs\" %(epoch + 1, epoch_time))\n",
    "    # Generate image after each epoch to check performance of the generator. Used for creating animated gif later.\n",
    "    with torch.no_grad():\n",
    "        gen_data = netG(fixed_noise).detach().cpu()\n",
    "    img_list.append(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True))\n",
    "\n",
    "    # Generate image to check performance of generator.\n",
    "    if((epoch+1) == 1 or (epoch+1) == params['num_epochs']/2):\n",
    "        with torch.no_grad():\n",
    "            gen_data = netG(fixed_noise).detach().cpu()\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
    "        plt.savefig(\"Epoch_%d {}\".format(params['dataset']) %(epoch+1))\n",
    "        plt.close('all')\n",
    "\n",
    "    # Save network weights.\n",
    "    if (epoch+1) % params['save_epoch'] == 0:\n",
    "        torch.save({\n",
    "            'netG' : netG.state_dict(),\n",
    "            'discriminator' : discriminator.state_dict(),\n",
    "            'netD' : netD.state_dict(),\n",
    "            'netQ' : netQ.state_dict(),\n",
    "            'optimD' : optimD.state_dict(),\n",
    "            'optimG' : optimG.state_dict(),\n",
    "            'params' : params\n",
    "            }, 'checkpoint/model_epoch_%d_{}'.format(params['dataset']) %(epoch+1))\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"-\"*50)\n",
    "print('Training finished!\\nTotal Time for Training: %.2fm' %(training_time / 60))\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Generate image to check performance of trained generator.\n",
    "with torch.no_grad():\n",
    "    gen_data = netG(fixed_noise).detach().cpu()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
    "plt.savefig(\"Epoch_%d_{}\".format(params['dataset']) %(params['num_epochs']))\n",
    "\n",
    "# Save network weights.\n",
    "torch.save({\n",
    "    'netG' : netG.state_dict(),\n",
    "    'discriminator' : discriminator.state_dict(),\n",
    "    'netD' : netD.state_dict(),\n",
    "    'netQ' : netQ.state_dict(),\n",
    "    'optimD' : optimD.state_dict(),\n",
    "    'optimG' : optimG.state_dict(),\n",
    "    'params' : params\n",
    "    }, 'checkpoint/model_final_{}'.format(params['dataset']))\n",
    "\n",
    "\n",
    "# Plot the training losses.\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Loss Curve {}\".format(params['dataset']))\n",
    "\n",
    "# Animation showing the improvements of the generator.\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "anim.save('infoGAN_{}.gif'.format(params['dataset']), dpi=80, writer='imagemagick')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
