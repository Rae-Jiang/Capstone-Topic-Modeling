{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacab size 142900\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "tokens = pkl.load(open(\"../../capstone_data_sent_tokens.p\", \"rb\"))\n",
    "all_tokens = pkl.load(open(\"../../capstone_data_all_tokens.p\", \"rb\"))\n",
    "print(\"vacab size\", len(set(all_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "MAX_VOCAB_SIZE = 100000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(MAX_VOCAB_SIZE))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#Global Parameters\n",
    "MAX_SEQ_LENGTH = 800\n",
    "BATCH_SIZE = 64\n",
    "START_LETTER = '<s>'\n",
    "VOCAB_SIZE = MAX_VOCAB_SIZE +2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seqs, token2id):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        \"\"\"\n",
    "        self.data_list = seqs\n",
    "        self.token2id = token2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        token_idx = [self.token2id[c] if c in self.token2id.keys() else UNK_IDX  for c in self.data_list[key][:MAX_WORD_LENGTH]]\n",
    "        return [token_idx, len(token_idx)]\n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        length_list.append(datum[1])\n",
    "        \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_SEQ_LENGTH-datum[1])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    ind_dec_order = np.argsort(length_list)[::-1]  ##desc order for speed\n",
    "    data_list = np.array(data_list)[ind_dec_order]\n",
    "    length_list = np.array(length_list)[ind_dec_order]\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list)]\n",
    "\n",
    "train_dataset = VocabDataset(tokens, token2id)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generator & Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @URL          : https://github.com/williamSYSU/TextGAN-PyTorch\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, padding_idx, gpu=False):\n",
    "        super(LSTMGenerator, self).__init__()\n",
    "        self.name = 'vanilla'\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.temperature = 1.0   \n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)  #\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp, hidden, need_hidden=False):\n",
    "        \"\"\"\n",
    "        Embeds input and applies LSTM\n",
    "        :param inp: batch_size * seq_len\n",
    "        :param hidden: (h, c)\n",
    "        :param need_hidden: if return hidden, use for sampling\n",
    "        \"\"\"\n",
    "        emb = self.embeddings(inp)  # batch_size * len * embedding_dim\n",
    "        \n",
    "        if len(inp.size()) == 1:\n",
    "            emb = emb.unsqueeze(1)  # batch_size * 1 * embedding_dim\n",
    "\n",
    "        out, hidden = self.lstm(emb, hidden)  # out: batch_size * seq_len * hidden_dim\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)  # out: (batch_size * seq_len) * hidden_dim\n",
    "        out = self.lstm2out(out)  # (batch_size * seq_len) * vocab_size\n",
    "        out = self.temperature * out  # temperature\n",
    "        pred = self.softmax(out)\n",
    "\n",
    "        if need_hidden:\n",
    "            return pred, hidden\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    def sample(self, num_samples, batch_size, start_letter=START_LETTER):\n",
    "        \"\"\"\n",
    "        Samples the network and returns num_samples samples of length max_seq_len.\n",
    "        :return samples: num_samples * max_seq_length (a sampled sequence in each row)\n",
    "        \"\"\"\n",
    "        num_batch = num_samples // batch_size + 1 if num_samples != batch_size else 1\n",
    "        samples = torch.zeros(num_batch * batch_size, self.max_seq_len).long()\n",
    "\n",
    "        # Generate sentences with multinomial sampling strategy\n",
    "        for b in range(num_batch):\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "            inp = torch.LongTensor([start_letter] * batch_size)\n",
    "            if self.gpu:\n",
    "                inp = inp.cuda()\n",
    "\n",
    "            for i in range(self.max_seq_len):\n",
    "                out, hidden = self.forward(inp, hidden, need_hidden=True)  # out: num_samples * vocab_size\n",
    "                next_token = torch.multinomial(torch.exp(out), 1)  # num_samples * 1 (sampling from each row)\n",
    "                samples[b * batch_size:(b + 1) * batch_size, i] = next_token.view(-1)\n",
    "                inp = next_token.view(-1)\n",
    "        samples = samples[:num_samples]\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                torch.nn.init.normal_(param, std=stddev)\n",
    "\n",
    "    def init_hidden(self, batch_size=BATCH_SIZE):\n",
    "        h = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "        c = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "\n",
    "        if self.gpu:\n",
    "            return h.cuda(), c.cuda()\n",
    "        else:\n",
    "            return h, c\n",
    "        \n",
    "class CNNDiscriminator(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, num_topics, filter_sizes, num_filters, padding_idx, gpu=False,\n",
    "                 dropout=0.2):\n",
    "        super(CNNDiscriminator, self).__init__()\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.feature_dim = sum(num_filters)\n",
    "        self.num_topics = num_topics\n",
    "        self.gpu = gpu\n",
    "\n",
    "        #layers\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, n, (f, embed_dim)) for (n, f) in zip(num_filters, filter_sizes)\n",
    "        ])\n",
    "        #TODO batch normalization\n",
    "        self.highway = nn.Linear(self.feature_dim, self.feature_dim)\n",
    "        self.feature2out = nn.Linear(self.feature_dim, 2)\n",
    "        self.feature2topic = nn.Linear(self.feature_dim, num_topics)   #num_topic topic model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Get final predictions of discriminator\n",
    "        :param inp: batch_size * seq_len\n",
    "        :return: pred: batch_size * 2\n",
    "        \"\"\"\n",
    "        feature = self.get_feature(inp)\n",
    "        pred = self.feature2out(self.dropout(feature))\n",
    "        topic = self.feature2topic(self.dropout(feature))\n",
    "        return pred, topic\n",
    "\n",
    "    def get_feature(self, inp):\n",
    "        \"\"\"\n",
    "        Get feature vector of given sentences\n",
    "        :param inp: batch_size * max_seq_len\n",
    "        :return: batch_size * feature_dim\n",
    "        \"\"\"\n",
    "        emb = self.embeddings(inp).unsqueeze(1)  # batch_size * 1 * max_seq_len * embed_dim\n",
    "        convs = [F.relu(conv(emb)).squeeze(3) for conv in self.convs]  # [batch_size * num_filter * length]\n",
    "        pools = [F.max_pool1d(conv, conv.size(2)).squeeze(2) for conv in convs]  # [batch_size * num_filter]\n",
    "        pred = torch.cat(pools, 1)  # tensor: batch_size * feature_dim\n",
    "        highway = self.highway(pred)\n",
    "        pred = torch.sigmoid(highway) * F.relu(highway) + (1. - torch.sigmoid(highway)) * pred  # highway\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def init_params(self):\n",
    "        for param in self.parameters():\n",
    "            if param.requires_grad and len(param.shape) > 0:\n",
    "                stddev = 1 / math.sqrt(param.shape[0])\n",
    "                torch.nn.init.normal_(param, std=stddev) #TODO may change init approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\min_{G,Q} \\max_{D} E_{x \\sim P_{data}}[\\log(D(x))]+E_{z \\sim P_z, c \\sim P_c}[\\log(1-D(G(z,c)))-\\lambda Q(c | G(z,c))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@URL   :    https://github.com/Natsu6767/InfoGAN-PyTorch/blob/4586919f2821b9b2e4aeff8a07c5003a5905c7f9/train.py\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "seed = 1123\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "print(\"Random Seed: \", seed)\n",
    "\n",
    "# Use GPU if available.\n",
    "device = torch.device(\"cuda:0\" if(torch.cuda.is_available()) else \"cpu\")\n",
    "print(device, \" will be used.\\n\")\n",
    "\n",
    "train_dataset = VocabDataset(tokens, token2id)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# Parameters\n",
    "embed_dim = 100\n",
    "hidden_dim =64\n",
    "num_topics = 20\n",
    "dis_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "dis_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialise the network\n",
    "generator = LSTMGenerator(embed_dim,hidden_dim,VOCAB_SIZE, MAX_SEQ_LEN, PAD_IDX).to(device) \n",
    "discriminator = CNNDiscriminator(embed_dim,VOCAB_SIZE, num_topics, dis_filter_sizes, dis_num_filters,PAD_IDX).to(device) #TODO params\n",
    "\n",
    "# Loss for discrimination between real and fake images.\n",
    "criterionD = nn.BCELoss()\n",
    "\n",
    "\n",
    "#Optimizers\n",
    "optimD = optim.Adam([{'params': discriminator.parameters()}], lr=learning_rate)\n",
    "optimG = optim.Adam([{'params': generator.parameters()}], lr=learning_rate)\n",
    "\n",
    "\n",
    "# Noise + Topic input TODO\n",
    "\n",
    "z = torch.randn(100, num_topics, 1, 1, device=device)\n",
    "if(params['num_dis_c'] != 0):\n",
    "    idx = np.arange(params['dis_c_dim']).repeat(10)\n",
    "    topic_c = torch.zeros(100, params['num_dis_c'], params['dis_c_dim'], device=device)\n",
    "    for i in range(params['num_dis_c']):\n",
    "        dis_c[torch.arange(0, 100), i, idx] = 1.0\n",
    "\n",
    "    dis_c = dis_c.view(100, -1, 1, 1)\n",
    "\n",
    "    fixed_noise = torch.cat((fixed_noise, dis_c), dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1000\n",
    "\n",
    "print(\"-\"*25)\n",
    "print(\"Starting Training Loop...\\n\")\n",
    "print('Epochs: %d\\nDataset: {}\\nBatch Size: %d\\nLength of Data Loader: %d'.format(params['dataset']) % (params['num_epochs'], params['batch_size'], len(dataloader)))\n",
    "print(\"-\"*25)\n",
    "\n",
    "start_time = time.time()\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for i, (data, _) in enumerate(train_loader, 0):\n",
    "        # Get batch size\n",
    "        b_size = data.size(0)\n",
    "        # Transfer data tensor to GPU/CPU (device)\n",
    "        real_data = data.to(device)\n",
    "        \n",
    "        # Updating discriminator\n",
    "        optimD.zero_grad()\n",
    "        # Real data\n",
    "        label = torch.full((b_size, ), real_label, device=device)\n",
    "        output1 = discriminator(real_data)\n",
    "        probs_real = netD(output1).view(-1)\n",
    "        loss_real = criterionD(probs_real, label)\n",
    "        # Calculate gradients.\n",
    "        loss_real.backward()\n",
    "        \n",
    "        # Fake data\n",
    "        label.fill_(fake_label)\n",
    "        noise, idx = noise_sample(params['num_dis_c'], params['dis_c_dim'], params['num_con_c'], params['num_z'], b_size, device)\n",
    "        fake_data = netG(noise)\n",
    "        output2 = discriminator(fake_data.detach())\n",
    "        probs_fake = netD(output2).view(-1)\n",
    "        loss_fake = criterionD(probs_fake, label)\n",
    "        # Calculate gradients.\n",
    "        loss_fake.backward()\n",
    "\n",
    "        # Net Loss for the discriminator\n",
    "        D_loss = loss_real + loss_fake\n",
    "        # Update parameters\n",
    "        optimD.step()\n",
    "        \n",
    "        # Updating Generator and QHead\n",
    "        optimG.zero_grad()\n",
    "\n",
    "        # Fake data treated as real.\n",
    "        output = discriminator(fake_data)\n",
    "        label.fill_(real_label)\n",
    "        probs_fake = netD(output).view(-1)\n",
    "        gen_loss = criterionD(probs_fake, label)\n",
    "\n",
    "        q_logits, q_mu, q_var = netQ(output)\n",
    "        target = torch.LongTensor(idx).to(device)\n",
    "        # Calculating loss for discrete latent code.\n",
    "        dis_loss = 0\n",
    "        for j in range(params['num_dis_c']):\n",
    "            dis_loss += criterionQ_dis(q_logits[:, j*10 : j*10 + 10], target[j])\n",
    "\n",
    "        # Calculating loss for continuous latent code.\n",
    "        con_loss = 0\n",
    "        if (params['num_con_c'] != 0):\n",
    "            con_loss = criterionQ_con(noise[:, params['num_z']+ params['num_dis_c']*params['dis_c_dim'] : ].view(-1, params['num_con_c']), q_mu, q_var)*0.1\n",
    "\n",
    "        # Net loss for generator.\n",
    "        G_loss = gen_loss + dis_loss + con_loss\n",
    "        # Calculate gradients.\n",
    "        G_loss.backward()\n",
    "        # Update parameters.\n",
    "        optimG.step()\n",
    "\n",
    "        # Check progress of training.\n",
    "        if i != 0 and i%100 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch+1, params['num_epochs'], i, len(dataloader), \n",
    "                    D_loss.item(), G_loss.item()))\n",
    "\n",
    "        # Save the losses for plotting.\n",
    "        G_losses.append(G_loss.item())\n",
    "        D_losses.append(D_loss.item())\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(\"Time taken for Epoch %d: %.2fs\" %(epoch + 1, epoch_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save network weights.\n",
    "torch.save({\n",
    "    'netG' : netG.state_dict(),\n",
    "    'discriminator' : discriminator.state_dict(),\n",
    "    'netD' : netD.state_dict(),\n",
    "    'netQ' : netQ.state_dict(),\n",
    "    'optimD' : optimD.state_dict(),\n",
    "    'optimG' : optimG.state_dict(),\n",
    "    'params' : params\n",
    "    }, 'checkpoint/model_final_{}'.format(params['dataset']))\n",
    "\n",
    "\n",
    "# Plot the training losses.\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Loss Curve {}\".format(params['dataset']))\n",
    "\n",
    "# Animation showing the improvements of the generator.\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "anim.save('infoGAN_{}.gif'.format(params['dataset']), dpi=80, writer='imagemagick')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
